{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tulipsa-Mallick/Task3_Neural_Style_Transfer/blob/main/neural_style_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ca9beGY1n2X"
      },
      "outputs": [],
      "source": [
        "# ðŸ“Œ Install required libraries\n",
        "!pip install -q tensorflow matplotlib\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RJl8hOA1ysb"
      },
      "outputs": [],
      "source": [
        "# ðŸ“Œ Import Libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import io\n",
        "from tensorflow.keras.applications import vgg19\n",
        "from tensorflow.keras.preprocessing import image as kp_image\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH6rqQho128b"
      },
      "outputs": [],
      "source": [
        "# ðŸ“Œ Preprocessing Functions\n",
        "\n",
        "def load_img(path_to_img):\n",
        "    target_size = (512, 512)  # Force fixed shape\n",
        "    img = Image.open(path_to_img)\n",
        "    img = img.convert('RGB')\n",
        "    img = img.resize(target_size, Image.LANCZOS)  # consistent resize\n",
        "    img = kp_image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return tf.keras.applications.vgg19.preprocess_input(img)\n",
        "\n",
        "\n",
        "def deprocess_img(processed_img):\n",
        "    x = processed_img.copy()\n",
        "    if len(x.shape) == 4:\n",
        "        x = tf.squeeze(x, 0)  # Remove batch dimension\n",
        "    x = x.numpy()  # Tensor to NumPy\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    x = x[:, :, ::-1]  # BGR to RGB\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0T6Swzqt15_B"
      },
      "outputs": [],
      "source": [
        "    from google.colab import files\n",
        "# ðŸ“Œ Upload content and style images\n",
        "uploaded = files.upload()\n",
        "content_path = list(uploaded.keys())[0]\n",
        "uploaded = files.upload()\n",
        "style_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Load both using your defined function\n",
        "content_image = load_img(content_path)\n",
        "style_image = load_img(style_path)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeWWAaxL19Wx"
      },
      "outputs": [],
      "source": [
        "content_image = load_img(content_path)\n",
        "style_image = load_img(style_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaqLzwjW2Fzi"
      },
      "outputs": [],
      "source": [
        "# ðŸ“Œ Display uploaded images\n",
        "def imshow(img, title=None):\n",
        "    out = deprocess_img(img)\n",
        "    plt.imshow(out)\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    plt.axis('off')\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1, 2, 1)\n",
        "imshow(content_image, 'Content Image')\n",
        "plt.subplot(1, 2, 2)\n",
        "imshow(style_image, 'Style Image')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m99mtICt2Iyl"
      },
      "outputs": [],
      "source": [
        "# ðŸ“Œ Build Model to Extract Style and Content\n",
        "vgg = vgg19.VGG19(include_top=False, weights='imagenet')\n",
        "vgg.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jM0hxdM12P2v"
      },
      "outputs": [],
      "source": [
        "# Layer configs\n",
        "style_layers = ['block1_conv1','block2_conv1','block3_conv1','block4_conv1','block5_conv1']\n",
        "content_layers = ['block5_conv2']\n",
        "num_style_layers = len(style_layers)\n",
        "num_content_layers = len(content_layers)\n",
        "\n",
        "def get_model():\n",
        "    outputs = [vgg.get_layer(name).output for name in (style_layers + content_layers)]\n",
        "    model = tf.keras.Model([vgg.input], outputs)\n",
        "    return model\n",
        "\n",
        "def gram_matrix(input_tensor):\n",
        "    channels = int(input_tensor.shape[-1])\n",
        "    a = tf.reshape(input_tensor, [-1, channels])\n",
        "    n = tf.shape(a)[0]\n",
        "    gram = tf.matmul(a, a, transpose_a=True)\n",
        "    return gram / tf.cast(n, tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zODv9rp2TV9"
      },
      "outputs": [],
      "source": [
        "# ðŸ“Œ Style and Content Features\n",
        "def get_features(model, content_img, style_img):\n",
        "    content_outputs = model(content_img)\n",
        "    style_outputs = model(style_img)\n",
        "\n",
        "    style_features = [gram_matrix(style_layer) for style_layer in style_outputs[:num_style_layers]]\n",
        "    content_features = content_outputs[num_style_layers:]\n",
        "    return style_features, content_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBQryT9d2WEt"
      },
      "outputs": [],
      "source": [
        "# ðŸ“Œ Compute Loss\n",
        "def compute_loss(model, loss_weights, init_image, gram_style_features, content_features):\n",
        "    input_tensor = tf.concat([init_image], axis=0)\n",
        "    outputs = model(input_tensor)\n",
        "\n",
        "    style_output_features = outputs[:num_style_layers]\n",
        "    content_output_features = outputs[num_style_layers:]\n",
        "\n",
        "    style_score = 0\n",
        "    content_score = 0\n",
        "\n",
        "    weight_per_style_layer = 1.0 / num_style_layers\n",
        "    for target_style, comb_style in zip(gram_style_features, style_output_features):\n",
        "        style_score += weight_per_style_layer * tf.reduce_mean(tf.square(gram_matrix(comb_style) - target_style))\n",
        "\n",
        "    weight_per_content_layer = 1.0 / num_content_layers\n",
        "    for target_content, comb_content in zip(content_features, content_output_features):\n",
        "        content_score += weight_per_content_layer * tf.reduce_mean(tf.square(comb_content - target_content))\n",
        "\n",
        "    style_weight, content_weight = loss_weights\n",
        "    total_loss = style_weight * style_score + content_weight * content_score\n",
        "\n",
        "    return total_loss, style_score, content_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LVia8UI2cGf"
      },
      "outputs": [],
      "source": [
        "# ðŸ“Œ Style Transfer with Optimizer\n",
        "@tf.function()\n",
        "def compute_grads(cfg):\n",
        "    with tf.GradientTape() as tape:\n",
        "        all_loss = compute_loss(**cfg)\n",
        "    total_loss = all_loss[0]\n",
        "    return tape.gradient(total_loss, cfg['init_image']), all_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQBx5whP2f7m"
      },
      "outputs": [],
      "source": [
        "# ðŸ“Œ Optimization Loop\n",
        "def run_style_transfer(content_img, style_img,\n",
        "                       num_iterations=1000,\n",
        "                       content_weight=1e3,\n",
        "                       style_weight=1e-2):\n",
        "\n",
        "    model = get_model()\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    style_features, content_features = get_features(model, content_img, style_img)\n",
        "    init_image = tf.Variable(content_img, dtype=tf.float32)\n",
        "\n",
        "    opt = tf.optimizers.Adam(learning_rate=5.0)\n",
        "\n",
        "    best_loss, best_img = float('inf'), None\n",
        "\n",
        "    loss_weights = (style_weight, content_weight)\n",
        "    cfg = {\n",
        "        'model': model,\n",
        "        'loss_weights': loss_weights,\n",
        "        'init_image': init_image,\n",
        "        'gram_style_features': style_features,\n",
        "        'content_features': content_features\n",
        "    }\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        grads, all_loss = compute_grads(cfg)\n",
        "        total_loss, style_score, content_score = all_loss\n",
        "        opt.apply_gradients([(grads, init_image)])\n",
        "        clipped = tf.clip_by_value(init_image, -103.939, 255.0 - 103.939)\n",
        "        init_image.assign(clipped)\n",
        "\n",
        "        if total_loss < best_loss:\n",
        "            best_loss = total_loss\n",
        "            best_img = init_image.numpy()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Iteration {i}:\")\n",
        "            print(f\"  Total loss: {total_loss:.4e}\")\n",
        "            print(f\"  Style loss: {style_score:.4e}\")\n",
        "            print(f\"  Content loss: {content_score:.4e}\")\n",
        "\n",
        "    return best_img, best_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cs7iqykP2mUb"
      },
      "outputs": [],
      "source": [
        "# ðŸ“Œ Run Style Transfer\n",
        "final_img, final_loss = run_style_transfer(content_image, style_image,num_iterations=800)\n",
        "print(\"Style transfer complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2mhcYco2pv8"
      },
      "outputs": [],
      "source": [
        "# ðŸ“Œ Show and Save Final Output\n",
        "plt.figure(figsize=(10,10))\n",
        "imshow(final_img, \"Final Output Image\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPcpTK0hV4tBDP7jou2VF2P",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}